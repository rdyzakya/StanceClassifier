{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/yusufsyaifudin/indonesia-ner/master/resources/ner/data_train.txt\"\n",
    "test_url = \"https://raw.githubusercontent.com/yusufsyaifudin/indonesia-ner/master/resources/ner/data_test.txt\"\n",
    "\n",
    "# read txt\n",
    "train = requests.get(train_url).text.splitlines()\n",
    "test = requests.get(test_url).text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "html_tag_pattern = re.compile(r\"(<.*?>)(.*?)(</.*?>)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<ORGANIZATION>', 'Universitas Gadjah Mada', '</ORGANIZATION>'),\n",
       " ('<PERSON>', 'Arie Sudjito', '</PERSON>'),\n",
       " ('<ORGANIZATION>', 'Partai Golkar', '</ORGANIZATION>'),\n",
       " ('<PERSON>', 'Aburizal Bakrie', '</PERSON>')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_tag_pattern.findall(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bio_tags(data):\n",
    "    new_data = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        term_with_tags = html_tag_pattern.findall(data[i])\n",
    "        joined_term_with_tags = [''.join(el) for el in term_with_tags]\n",
    "        text = data[i]\n",
    "\n",
    "        for j,joined_term_with_tag in enumerate(joined_term_with_tags):\n",
    "            text = text.replace(joined_term_with_tag, term_with_tags[j][1])\n",
    "        \n",
    "        tokenized_text = word_tokenize(text)\n",
    "        bio_tags = ['O' for _ in range(len(tokenized_text))]\n",
    "        for term in term_with_tags:\n",
    "            if term[0] != '<PERSON>':\n",
    "                continue\n",
    "            term = term[1]\n",
    "            tokenized_term = word_tokenize(term)\n",
    "\n",
    "            for k in range(0,len(tokenized_text)-len(tokenized_term)+1,1):\n",
    "                if tokenized_text[k:k+len(tokenized_term)] == tokenized_term:\n",
    "                    bio_tags[k] = 'B-PERSON'\n",
    "                    for l in range(1,len(tokenized_term)):\n",
    "                        bio_tags[k+l] = 'I-PERSON'\n",
    "            \n",
    "        new_data.append([tokenized_text,bio_tags])\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = create_bio_tags(train)\n",
    "tokenized_test = create_bio_tags(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./interim/data.txt\"\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    for data in tokenized_train:\n",
    "        for token, tag in zip(data[0], data[1]):\n",
    "            # make token unicode\n",
    "            token = token.encode('unicode_escape').decode('utf-8')\n",
    "            f.write(token + \"\\t\" + tag + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    for data in tokenized_test:\n",
    "        for token, tag in zip(data[0], data[1]):\n",
    "            # make token unicode\n",
    "            token = token.encode('unicode_escape').decode('utf-8')\n",
    "            f.write(token + \"\\t\" + tag + \"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5045f1ed516028e6ba3c78ae58e34f2955ee8afe7e35fc1835a968676e80520"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
